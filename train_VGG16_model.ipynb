{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_VGG16_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nvhien1961999/Covid19_auto_detecting_vision_transformer_model/blob/main/train_VGG16_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgGY516LwS65",
        "outputId": "925d5796-eff5-4462-a338-cc1e54445327"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29pyLUHhv-mm"
      },
      "source": [
        "root_folder = '/content/gdrive/MyDrive/VGG' + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxncW8oBwXil"
      },
      "source": [
        "# khoi tao toc do hoc ban dau so lan lap va so anh moi lan lap\n",
        "INIT_LR = 1e-3\n",
        "EPOCHS=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttsBBcEvwULB"
      },
      "source": [
        "# import thu vien\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "import pickle\n",
        "import time\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(src):\n",
        "    src = src + '/'\n",
        "    #resize\n",
        "    print(\"[INFO] loading images...\")\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "    num_img = 0\n",
        "\n",
        "    # Lặp qua các folder con trong thư mục raw\n",
        "    for folder in listdir(src):\n",
        "        if folder!='.DS_Store':\n",
        "            print(\"Folder: \",folder)\n",
        "            # Lặp qua các file trong từng thư mục chứa các anh\n",
        "            for file in listdir(src  + folder):\n",
        "                if file!='.DS_Store':\n",
        "                    print(\"File: \", file + \", folder: \",folder)\n",
        "                    data.append( cv2.resize(cv2.imread(src + folder + \"/\" + file),dsize=(224,224)))\n",
        "                    labels.append( folder)\n",
        "                    num_img += 1\n",
        "\n",
        "    data = np.array(data)\n",
        "    labels = np.array(labels)#.reshape(-1,1)\n",
        "\n",
        "    from sklearn.preprocessing import LabelBinarizer\n",
        "    encoder = LabelBinarizer()\n",
        "    labels = encoder.fit_transform(labels)\n",
        "    print(labels)\n",
        "\n",
        "    return data, labels"
      ],
      "metadata": {
        "id": "SsmxidGFLDNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainX, trainY = load_data('/content/gdrive/MyDrive/dataset/splitted_dataset/train')\n",
        "valX, valY = load_data('/content/gdrive/MyDrive/dataset/splitted_dataset/val')"
      ],
      "metadata": {
        "id": "TuIUceMgN0fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVvbv0wmQzK_"
      },
      "source": [
        "# tao doi tuong de tang du lieu huan luyen\n",
        "trainAug = ImageDataGenerator(\n",
        "\trotation_range=15,\n",
        "\tfill_mode=\"nearest\"\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpC3YVtAQ3Dy"
      },
      "source": [
        "def get_model():\n",
        "  # load mang VGG16 vo hieu cac lop FC\n",
        "  baseModel = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))\n",
        "  headModel = baseModel.output\n",
        "  headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n",
        "  headModel = Flatten(name=\"flatten\")(headModel)\n",
        "  headModel = Dense(64, activation=\"relu\")(headModel)\n",
        "  headModel = Dropout(0.5)(headModel)\n",
        "  headModel = Dense(3, activation=\"softmax\")(headModel)\n",
        "  # place the head FC model on top of the base model (this will become\n",
        "  # the actual model we will train)\n",
        "  model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "  for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "  print(\"[INFO] compiling model...\")\n",
        "  opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "  print(\"[INFO] training head...\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptZN3ta-Q6Fr",
        "outputId": "9ef30983-a1df-4b5f-ea2f-1c92195c7f1a"
      },
      "source": [
        "model = get_model()\n",
        "filepath=\"weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n",
            "58900480/58889256 [==============================] - 2s 0us/step\n",
            "[INFO] compiling model...\n",
            "[INFO] training head...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "WYNYiv_ogROE",
        "outputId": "b39db24b-fb18-4b19-fed5-7969a4e35e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 1, 1, 512)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                32832     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,747,715\n",
            "Trainable params: 33,027\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6Fzq8b-RFbZ",
        "outputId": "c45d7edc-9727-4d32-f0f4-79da8ab2d73c"
      },
      "source": [
        "start = time.time()\n",
        "vgghist = model.fit_generator(\n",
        "    trainAug.flow(trainX,trainY),\n",
        "    validation_data=(valX,valY),\n",
        "    epochs=50,\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "end = time.time()\n",
        "print(\"Training time: \", end - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "324/324 [==============================] - ETA: 0s - loss: 0.6463 - accuracy: 0.5385"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzJ7wZrIa03f"
      },
      "source": [
        "model.save(root_folder + \"filepath.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qj6qJNxhiP-2"
      },
      "source": [
        "import json\n",
        "# Get the dictionary containing each metric and the loss for each epoch\n",
        "history_dict = vgghist.history\n",
        "# Save it under the form of a json file\n",
        "json.dump(history_dict, open(root_folder + \"vgghist.history\", 'w'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NN1GbfSVdNNP"
      },
      "source": [
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(valX.shape)\n",
        "print(valY.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrTcLqy0s6PB"
      },
      "source": [
        "f = open(root_folder + \"training_time.txt\", \"w\")\n",
        "f.write(str(end-start))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}